<h1 align="center">
    <img width="400" src="r.png" />
</h1>

<p align="center">
# EfolioB-RRC
</p>

<p align="center">
# TESTE com ANTLR e Python
</p>

üìå EfolioB de RRC - √°rvore de decis√£o,  K vizinhos mais pr√≥ximos e Redes neuronais
------------------
O e-f√≥lio B consiste essencialmente na realiza√ß√£o da atividade de aprendizagem: usando bibliotecas em R, usando dados e um indicador objetivo √† sua escolha.

Sugere-se que considere como observa√ß√µes dados de pa√≠ses e anos, e procure aprender o que influencia um dos indicadores de um dos objetivos de desenvolvimento sustent√°vel (dados no pordata).

1) Refira no f√≥rum do espa√ßo central o indicador que est√° a procurar aprender, de modo a evitar colis√µes de trabalhos entre estudantes. Utilize o t√≥pico "[E-f√≥lio B] Escolha de indicador"

2) Selecione entre 3 e 6 vari√°veis independentes que representem observa√ß√µes que possam influenciar o indicador escolhido.

2) Aplique os 3 m√©todos de aprendizagem (√°rvores de decis√£o, k vizinhos mais pr√≥ximos e redes neuronais), calculando a performance de cada m√©todo, e indicando as vari√°veis observ√°veis mais √∫teis.

3) Apresente um relat√≥rio (m√°x. 2 p√°ginas, excluindo folha de rosto e anexos) com a seguinte estrutura:

indicador escolhido, descri√ß√£o das vari√°veis independentes, e porque pensa que influenciam o indicador, n¬∫ de exemplos/observa√ß√µes utilizados para treino e para teste
descri√ß√£o da implementa√ß√£o de cada m√©todo, com foco nas decis√µes tomadas (ex. tratamento, categoriza√ß√£o ou normaliza√ß√£o dos dados, necess√°rios para aplicar cada algoritmo)
conclus√µes sobre os resultados obtidos, a performance de cada m√©todo e vari√°veis mais √∫teis
anexo onde dever√° colocar o c√≥digo usado e tabelas de resultados

Crit√©rios de avalia√ß√£o:

Implementa√ß√£o de √°rvore de decis√£o: 1 valor
Implementa√ß√£o de K vizinhos mais pr√≥ximos: 1 valor
Implementa√ß√£o de Redes neuronais: 1 valor
Relat√≥rio (organiza√ß√£o, clareza, fundamenta√ß√£o): 1 valor

## Pr√©-requisitos

- R: the R Project for Statistical Computing - https://www.r-project.org
- https://www.pordata.pt/ods/goal/trabalho+digno+e+crescimento+economico-8
- Excell

## Passo a Passo

### 1. Importar os ficheros em Excell

Importamos todos os ficheiros do indicador e as variaveis.

### 2. Converter os Ficheiros para formato CSV

Converter os dados para CSV com Excell.

### 3. Preparar o Ambiente R

Certifique-se de que Rstudio est√° instalado.

### 4. Escrever e executar o Script de Teste em R

Executamos o comando para testar a interpreta√ß√£o do programa

<pre> source("efolioBfinal.R", echo=TRUE) </pre>


Resultado: 
> 
> #============================================================================
> # UC: 21097 - Racioc√≠nio e Representa√ß√£o do Conhecimento - 02 - UAb
 .... [TRUNCATED] 

> # Instalar pacotes necess√°rios se n√£o estiverem instalados
> if (!require('randomForest')) install.packages('randomForest', dependencies=TRUE)

> if (!require('caret')) install.packages('caret', dependencies=TRUE)

> if (!require('nnet')) install.packages('nnet', dependencies=TRUE)

> if (!require('ggplot2')) install.packages('ggplot2', dependencies=TRUE)

> # Carregar bibliotecas
> library(randomForest)

> library(caret)

> library(nnet)

> library(ggplot2)

> # Carregar os dados
> dados <- read.csv("dados_jovens.csv", header = TRUE, sep = ";", stringsAsFactors = FALSE, fill = TRUE)

> # Visualizar os dados para verificar se foram carregados corretamente
> head(dados)
         Paises Anos   X1   X2  X3   X4
1 DE - Alemanha 2009 12,9 11,1 3,4 -5,7
2 DE - Alemanha 2011   11 11,6 3,4  3,9
3 DE - Alemanha 2013  9,9  9,8 3,2  0,4
4 DE - Alemanha 2015  9,6 10,1 3,1  1,5
5 DE - Alemanha 2017  9,6 10,1   3  2,7
6 DE - Alemanha 2019  8,6 10,3 2,9  1,1

> # Verificar a estrutura dos dados
> str(dados)
'data.frame':	651 obs. of  6 variables:
 $ Paises: chr  "DE - Alemanha" "DE - Alemanha" "DE - Alemanha" "DE - Alemanha" ...
 $ Anos  : int  2009 2011 2013 2015 2017 2019 2021 2023 2009 2011 ...
 $ X1    : chr  "12,9" "11" "9,9" "9,6" ...
 $ X2    : chr  "11,1" "11,6" "9,8" "10,1" ...
 $ X3    : chr  "3,4" "3,4" "3,2" "3,1" ...
 $ X4    : chr  "-5,7" "3,9" "0,4" "1,5" ...

> # Converter vari√°veis de caracteres para num√©ricos (necess√°rio para processamento correto)
> dados$X1 <- as.numeric(sub(",", ".", dados$X1))

> dados$X2 <- as.numeric(sub(",", ".", dados$X2))

> dados$X3 <- as.numeric(sub(",", ".", dados$X3))

> dados$X4 <- as.numeric(sub(",", ".", dados$X4))

> # Remover linhas com valores NA
> dados <- na.omit(dados)

> # Adicionar coluna Meta_Atingida: 1 para sim e 2 para n√£o
> dados$Meta_Atingida <- ifelse(dados$X1 <= 9, 1, 2)

> # Visualizar os dados
> head(dados)
         Paises Anos   X1   X2  X3   X4 Meta_Atingida
1 DE - Alemanha 2009 12.9 11.1 3.4 -5.7             2
2 DE - Alemanha 2011 11.0 11.6 3.4  3.9             2
3 DE - Alemanha 2013  9.9  9.8 3.2  0.4             2
4 DE - Alemanha 2015  9.6 10.1 3.1  1.5             2
5 DE - Alemanha 2017  9.6 10.1 3.0  2.7             2
6 DE - Alemanha 2019  8.6 10.3 2.9  1.1             1

> # Separar vari√°veis independentes e dependente
> variaveis_independentes <- dados[, c("X2", "X3", "X4")]

> variavel_dependente <- dados$Meta_Atingida

> # Garantir que a vari√°vel dependente √© um fator
> variavel_dependente <- as.factor(variavel_dependente)

> # Combinar vari√°veis independentes e dependente novamente para formar os conjuntos de treino e teste
> dados_completo <- cbind(variaveis_independent .... [TRUNCATED] 

> # Divis√£o em conjuntos de treino e teste
> set.seed(123)

> indices <- sample(1:nrow(dados_completo), size = 0.7 * nrow(dados_completo))

> treino <- dados_completo[indices, ]

> teste <- dados_completo[-indices, ]

> ### 4.1. Tarefa 4.1: √Årvores de Decis√£o
> 
> # Treinar o modelo de √°rvore de decis√£o
> arvore_modelo <- randomForest(x = treino[, 1:3], y = treino[, .... [TRUNCATED] 

> print(arvore_modelo)

Call:
 randomForest(x = treino[, 1:3], y = treino[, 4], ntree = 100,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 100
No. of variables tried at each split: 1

        OOB estimate of  error rate: 21.85%
Confusion matrix:
   1   2 class.error
1 10  24  0.70588235
2  9 108  0.07692308

> # Confirmar que foi uma classifica√ß√£o e n√£o uma regress√£o
> print(arvore_modelo$type)
[1] "classification"

> # Fazer previs√µes no conjunto de teste
> pred_arvore <- predict(arvore_modelo, teste[, 1:3])

> # Avaliar a performance do modelo
> cat("√Årvore de Decis√£o - Matriz de Confus√£o:\n")
√Årvore de Decis√£o - Matriz de Confus√£o:

> conf_mat_arvore <- confusionMatrix(pred_arvore, teste[, 4])

> print(conf_mat_arvore)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  3  6
         2 10 47
                                          
               Accuracy : 0.7576          
                 95% CI : (0.6364, 0.8546)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.8599          
                                          
                  Kappa : 0.133           
                                          
 Mcnemar's Test P-Value : 0.4533          
                                          
            Sensitivity : 0.23077         
            Specificity : 0.88679         
         Pos Pred Value : 0.33333         
         Neg Pred Value : 0.82456         
             Prevalence : 0.19697         
         Detection Rate : 0.04545         
   Detection Prevalence : 0.13636         
      Balanced Accuracy : 0.55878         
                                          
       'Positive' Class : 1               
                                          

> # Import√¢ncia das Vari√°veis na √Årvore de Decis√£o
> cat("Import√¢ncia das Vari√°veis:\n")
Import√¢ncia das Vari√°veis:

> print(importance(arvore_modelo))
          1          2 MeanDecreaseAccuracy MeanDecreaseGini
X2 6.828680  7.9633314             9.190741         21.54032
X3 2.895261 -0.7445043             1.022850         12.60203
X4 2.272132  3.0900849             3.872191         16.29301

> varImpPlot(arvore_modelo)

> ### 4.2. Tarefa 4.2: K Vizinhos Mais Pr√≥ximos
> 
> # Treinar o modelo de KNN
> knn_modelo <- knn3(x = treino[, 1:3], y = treino[, 4], k = 3)

> print(knn_modelo)
3-nearest neighbor model
Training set outcome distribution:

  1   2 
 34 117 


> # Fazer previs√µes no conjunto de teste
> pred_knn <- predict(knn_modelo, teste[, 1:3])

> # Ajustar n√≠veis para a matriz de confus√£o
> pred_knn <- factor(max.col(pred_knn), levels = levels(teste$Meta_Atingida))

> # Avaliar a performance do modelo
> cat("K Vizinhos Mais Pr√≥ximos - Matriz de Confus√£o:\n")
K Vizinhos Mais Pr√≥ximos - Matriz de Confus√£o:

> conf_mat_knn <- confusionMatrix(pred_knn, teste$Meta_Atingida)

> print(conf_mat_knn)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  3 11
         2 10 42
                                          
               Accuracy : 0.6818          
                 95% CI : (0.5556, 0.7911)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.9936          
                                          
                  Kappa : 0.0226          
                                          
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.23077         
            Specificity : 0.79245         
         Pos Pred Value : 0.21429         
         Neg Pred Value : 0.80769         
             Prevalence : 0.19697         
         Detection Rate : 0.04545         
   Detection Prevalence : 0.21212         
      Balanced Accuracy : 0.51161         
                                          
       'Positive' Class : 1               
                                          

> ### 4.3. Tarefa 4.3: Redes Neuronais
> 
> # Treinar o modelo de rede neural
> rede_modelo <- nnet(Meta_Atingida ~ ., data = treino, size = 5, linout .... [TRUNCATED] 

> print(rede_modelo)
a 3-5-1 network with 26 weights
inputs: X2 X3 X4 
output(s): Meta_Atingida 
options were - entropy fitting 

> # Mostrar os pesos da rede
> cat("Pesos da Rede Neuronal:\n")
Pesos da Rede Neuronal:

> print(rede_modelo$wts)
 [1] -9454.571838  1028.218793   400.613691  -411.659311 -9008.186211 -7025.462864  7202.303440  3142.600517   111.510864   -12.820578
[11]  -366.655103    92.255667   -63.675527    57.783893    35.198519   -44.141759  8426.473816  -369.620252 -1012.305431 -1044.660635
[21]   -62.009386     2.750503  2700.415784  -156.953272    62.405023    -1.669902

> # Fazer previs√µes no conjunto de teste
> pred_rede <- predict(rede_modelo, teste[, 1:3], type = "class")

> # Ajustar n√≠veis para a matriz de confus√£o
> pred_rede <- factor(pred_rede, levels = levels(teste$Meta_Atingida))

> # Avaliar a performance do modelo
> cat("Redes Neurais - Matriz de Confus√£o:\n")
Redes Neurais - Matriz de Confus√£o:

> conf_mat_rede <- confusionMatrix(pred_rede, teste$Meta_Atingida)

> print(conf_mat_rede)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  1  5
         2 12 48
                                          
               Accuracy : 0.7424          
                 95% CI : (0.6199, 0.8422)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.9145          
                                          
                  Kappa : -0.0219         
                                          
 Mcnemar's Test P-Value : 0.1456          
                                          
            Sensitivity : 0.07692         
            Specificity : 0.90566         
         Pos Pred Value : 0.16667         
         Neg Pred Value : 0.80000         
             Prevalence : 0.19697         
         Detection Rate : 0.01515         
   Detection Prevalence : 0.09091         
      Balanced Accuracy : 0.49129         
                                          
       'Positive' Class : 1               
                                          

> ### Resultados e Reflex√µes
> 
> # √Årvore de Decis√£o - Resultados
> cat("\nResultados - √Årvore de Decis√£o:\n")

Resultados - √Årvore de Decis√£o:

> cat("Erro M√©dio Estimado: ", mean(arvore_modelo$err.rate[,1]), "\n")
Erro M√©dio Estimado:  0.2340981 

> cat("Import√¢ncia das Vari√°veis:\n")
Import√¢ncia das Vari√°veis:

> print(importance(arvore_modelo))
          1          2 MeanDecreaseAccuracy MeanDecreaseGini
X2 6.828680  7.9633314             9.190741         21.54032
X3 2.895261 -0.7445043             1.022850         12.60203
X4 2.272132  3.0900849             3.872191         16.29301

> print(conf_mat_arvore)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  3  6
         2 10 47
                                          
               Accuracy : 0.7576          
                 95% CI : (0.6364, 0.8546)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.8599          
                                          
                  Kappa : 0.133           
                                          
 Mcnemar's Test P-Value : 0.4533          
                                          
            Sensitivity : 0.23077         
            Specificity : 0.88679         
         Pos Pred Value : 0.33333         
         Neg Pred Value : 0.82456         
             Prevalence : 0.19697         
         Detection Rate : 0.04545         
   Detection Prevalence : 0.13636         
      Balanced Accuracy : 0.55878         
                                          
       'Positive' Class : 1               
                                          

> # K Vizinhos Mais Pr√≥ximos - Resultados
> cat("\nResultados - K Vizinhos Mais Pr√≥ximos:\n")

Resultados - K Vizinhos Mais Pr√≥ximos:

> print(conf_mat_knn)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  3 11
         2 10 42
                                          
               Accuracy : 0.6818          
                 95% CI : (0.5556, 0.7911)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.9936          
                                          
                  Kappa : 0.0226          
                                          
 Mcnemar's Test P-Value : 1.0000          
                                          
            Sensitivity : 0.23077         
            Specificity : 0.79245         
         Pos Pred Value : 0.21429         
         Neg Pred Value : 0.80769         
             Prevalence : 0.19697         
         Detection Rate : 0.04545         
   Detection Prevalence : 0.21212         
      Balanced Accuracy : 0.51161         
                                          
       'Positive' Class : 1               
                                          

> # Redes Neurais - Resultados
> cat("\nResultados - Redes Neurais:\n")

Resultados - Redes Neurais:

> print(conf_mat_rede)
Confusion Matrix and Statistics

          Reference
Prediction  1  2
         1  1  5
         2 12 48
                                          
               Accuracy : 0.7424          
                 95% CI : (0.6199, 0.8422)
    No Information Rate : 0.803           
    P-Value [Acc > NIR] : 0.9145          
                                          
                  Kappa : -0.0219         
                                          
 Mcnemar's Test P-Value : 0.1456          
                                          
            Sensitivity : 0.07692         
            Specificity : 0.90566         
         Pos Pred Value : 0.16667         
         Neg Pred Value : 0.80000         
             Prevalence : 0.19697         
         Detection Rate : 0.01515         
   Detection Prevalence : 0.09091         
      Balanced Accuracy : 0.49129         
                                          
       'Positive' Class : 1               
                                          

> ### Conclus√£o
> cat("\nConclus√£o:\n")

Conclus√£o:

> cat("Ap√≥s aplicar os tr√™s m√©todos de aprendizagem supervisionada, foram observados os seguintes resultados:\n")
Ap√≥s aplicar os tr√™s m√©todos de aprendizagem supervisionada, foram observados os seguintes resultados:

> cat("√Årvore de Decis√£o apresentou um erro m√©dio estimado de ", mean(arvore_modelo$err.rate[,1]), " e mostrou que a vari√°vel mais importante foi X2.\ ..." ... [TRUNCATED] 
√Årvore de Decis√£o apresentou um erro m√©dio estimado de  0.2340981  e mostrou que a vari√°vel mais importante foi X2.

> cat("O m√©todo K Vizinhos Mais Pr√≥ximos teve uma precis√£o de ", conf_mat_knn$overall['Accuracy'], ".\n")
O m√©todo K Vizinhos Mais Pr√≥ximos teve uma precis√£o de  0.6818182 .

> cat("O m√©todo de Redes Neurais teve uma precis√£o de ", conf_mat_rede$overall['Accuracy'], ".\n")
O m√©todo de Redes Neurais teve uma precis√£o de  0.7424242 .

> cat("Analisando os resultados, podemos concluir que o modelo de √Årvores de Decis√£o apresentou melhor performance em termos de erro m√©dio, enquanto o ..." ... [TRUNCATED] 
Analisando os resultados, podemos concluir que o modelo de √Årvores de Decis√£o apresentou melhor performance em termos de erro m√©dio, enquanto o modelo de Redes Neurais teve uma precis√£o ligeiramente inferior. O K Vizinhos Mais Pr√≥ximos teve a menor precis√£o entre os tr√™s m√©todos.
> 
O projeto foi feito em Rstudio 


The project was done with Rstudio


<img src="print.png" alt="page-home">

<img src="print2.png" alt="page-home">
üîß Tecnologias utilizadas:
------------------

- Rstudio
- Excell 

üí¨ Fale comigo
------------------
[*Entre em contato comigo*](https://www.linkedin.com/in/ivo-baptista-3712144/)
